{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate synthetic Data for Telecom Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from faker import Faker\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "# Parameters\n",
    "n_users = 2000\n",
    "n_towers = 50\n",
    "n_pois = 100\n",
    "n_records = 5000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      user_id  tower_id           timestamp  age  gender  interest  \\\n",
      "0         425        48 2024-01-01 00:00:00   27    Male  Shopping   \n",
      "1        1810        46 2024-01-01 00:01:00   30   Other      Food   \n",
      "2        1311        23 2024-01-01 00:02:00   28    Male    Travel   \n",
      "3        1201        35 2024-01-01 00:03:00   39    Male    Sports   \n",
      "4        1481        33 2024-01-01 00:04:00   31  Female      Food   \n",
      "...       ...       ...                 ...  ...     ...       ...   \n",
      "4995      983        16 2024-01-04 11:15:00   18   Other      Food   \n",
      "4996      595        35 2024-01-04 11:16:00   58    Male  Shopping   \n",
      "4997      537         6 2024-01-04 11:17:00   62   Other    Sports   \n",
      "4998     1929        47 2024-01-04 11:18:00   52    Male      Food   \n",
      "4999     1197        23 2024-01-04 11:19:00   51    Male      Food   \n",
      "\n",
      "     socioeconomic_profile                        brand_affinity   latitude  \\\n",
      "0                     High                         [Apple, Nike]  51.513284   \n",
      "1                     High                        [Adidas, Nike]  51.512703   \n",
      "2                      Low         [Sony, Nike, Samsung, Adidas]  51.511610   \n",
      "3                      Low                         [Sony, Apple]  51.510058   \n",
      "4                     High               [Adidas, Samsung, Sony]  51.510825   \n",
      "...                    ...                                   ...        ...   \n",
      "4995                   Low              [Samsung, Adidas, Apple]  51.511935   \n",
      "4996                Middle               [Nike, Samsung, Adidas]  51.510058   \n",
      "4997                  High                  [Sony, Adidas, Nike]  51.509876   \n",
      "4998                   Low           [Adidas, Apple, Nike, Sony]  51.511020   \n",
      "4999                Middle  [Apple, Adidas, Samsung, Sony, Nike]  51.511610   \n",
      "\n",
      "      longitude  \n",
      "0     -0.151258  \n",
      "1     -0.136721  \n",
      "2     -0.137883  \n",
      "3     -0.140600  \n",
      "4     -0.144733  \n",
      "...         ...  \n",
      "4995  -0.139124  \n",
      "4996  -0.140600  \n",
      "4997  -0.148981  \n",
      "4998  -0.142080  \n",
      "4999  -0.137883  \n",
      "\n",
      "[5000 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# Generate synthetic mobile tower logs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Number of towers\n",
    "n_towers = 50\n",
    "\n",
    "# Define the bounding box for London streets\n",
    "latitude_range = (51.5098, 51.5155)\n",
    "longitude_range = (-0.1515, -0.1357)\n",
    "\n",
    "# Generate random tower coordinates within the bounding box\n",
    "towers = pd.DataFrame({\n",
    "    'tower_id': range(1, n_towers + 1),\n",
    "    'latitude': np.random.uniform(latitude_range[0], latitude_range[1], n_towers),\n",
    "    'longitude': np.random.uniform(longitude_range[0], longitude_range[1], n_towers)\n",
    "})\n",
    "\n",
    "# Display the updated towers DataFrame\n",
    "#print(towers)\n",
    "brands = ['Nike', 'Apple', 'Samsung', 'Adidas', 'Sony']\n",
    "eco_profiles = ['Low', 'Middle', 'High']\n",
    "users = pd.DataFrame({\n",
    "    'user_id': range(1, n_users + 1),\n",
    "    'age': np.random.randint(18, 65, n_users),\n",
    "    'gender': np.random.choice(['Male', 'Female', 'Other'], n_users),\n",
    "    'interest': np.random.choice(['Sports', 'Shopping', 'Food', 'Travel'], n_users),\n",
    "    'socioeconomic_profile': np.random.choice(eco_profiles, n_users),\n",
    "    'brand_affinity': np.random.choice(brands, n_users)\n",
    "})\n",
    "\n",
    "# Adding 'brand_affinity' with random selection of 0 to 5 brands\n",
    "users['brand_affinity'] = [\n",
    "    np.random.choice(brands, np.random.randint(1, 6), replace=False).tolist()  # 0 to 5 brands per user\n",
    "    for _ in range(n_users)\n",
    "]\n",
    "\n",
    "logs = pd.DataFrame({\n",
    "    'user_id': np.random.choice(users['user_id'], n_records),\n",
    "    'tower_id': np.random.choice(towers['tower_id'], n_records),\n",
    "    'timestamp': pd.date_range(start='2024-01-01', periods=n_records, freq='min'),\n",
    "})\n",
    "\n",
    "#print(users.head(10))\n",
    "#print(towers.head(10))\n",
    "\n",
    "# Step 1: Join logs with users on 'user_id'\n",
    "logs_users = logs.merge(users, on='user_id', how='inner')\n",
    "\n",
    "# Step 2: Join the result with towers on 'tower_id'\n",
    "final_data = logs_users.merge(towers, on='tower_id', how='inner')\n",
    "\n",
    "# Display the final joined dataset\n",
    "print(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        name            category  latitude  longitude\n",
      "0      Oxford Circus Station           Transport   51.5154    -0.1419\n",
      "1                 Selfridges                Mall   51.5145    -0.1515\n",
      "2      Primark Oxford Street            Shopping   51.5142    -0.1467\n",
      "3      John Lewis & Partners            Shopping   51.5152    -0.1439\n",
      "4    Oxford Street Starbucks          Restaurant   51.5147    -0.1475\n",
      "5                    Hamleys            Shopping   51.5121    -0.1409\n",
      "6  Regent Street Apple Store            Shopping   51.5133    -0.1418\n",
      "7          Piccadilly Circus  Tourist Attraction   51.5098    -0.1357\n",
      "8            The Argyll Arms          Restaurant   51.5146    -0.1412\n",
      "9       Regent Street Cinema       Entertainment   51.5131    -0.1454\n"
     ]
    }
   ],
   "source": [
    "# Generate synthetic POI data\n",
    "# Synthetic Points of Interest for Oxford Street\n",
    "oxford_street_pois = [\n",
    "    {\"name\": \"Oxford Circus Station\", \"category\": \"Transport\", \"latitude\": 51.5154, \"longitude\": -0.1419},\n",
    "    {\"name\": \"Selfridges\", \"category\": \"Mall\", \"latitude\": 51.5145, \"longitude\": -0.1515},\n",
    "    {\"name\": \"Primark Oxford Street\", \"category\": \"Shopping\", \"latitude\": 51.5142, \"longitude\": -0.1467},\n",
    "    {\"name\": \"John Lewis & Partners\", \"category\": \"Shopping\", \"latitude\": 51.5152, \"longitude\": -0.1439},\n",
    "    {\"name\": \"Oxford Street Starbucks\", \"category\": \"Restaurant\", \"latitude\": 51.5147, \"longitude\": -0.1475}\n",
    "]\n",
    "\n",
    "# Synthetic Points of Interest for Regent Street\n",
    "regent_street_pois = [\n",
    "    {\"name\": \"Hamleys\", \"category\": \"Shopping\", \"latitude\": 51.5121, \"longitude\": -0.1409},\n",
    "    {\"name\": \"Regent Street Apple Store\", \"category\": \"Shopping\", \"latitude\": 51.5133, \"longitude\": -0.1418},\n",
    "    {\"name\": \"Piccadilly Circus\", \"category\": \"Tourist Attraction\", \"latitude\": 51.5098, \"longitude\": -0.1357},\n",
    "    {\"name\": \"The Argyll Arms\", \"category\": \"Restaurant\", \"latitude\": 51.5146, \"longitude\": -0.1412},\n",
    "    {\"name\": \"Regent Street Cinema\", \"category\": \"Entertainment\", \"latitude\": 51.5131, \"longitude\": -0.1454}\n",
    "]\n",
    "\n",
    "# Combine the data into a single DataFrame\n",
    "pois = pd.DataFrame(oxford_street_pois + regent_street_pois)\n",
    "\n",
    "print(pois)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Audience Insights\n",
    "- Using clustering to segment users based on demographics and location patterns:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Prepare user demographic features\n",
    "user_features = users[['age']].join(pd.get_dummies(users['gender']))\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(user_features)\n",
    "\n",
    "# Apply clustering\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "users['segment'] = kmeans.fit_predict(scaled_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Movement Insights\n",
    "- Using trajectory analysis to study origin-destination patterns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11369/1923746000.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  movements['distance'] = np.sqrt(\n"
     ]
    }
   ],
   "source": [
    "# Merge logs with towers for location data\n",
    "logs = logs.merge(towers, on='tower_id', how='left')\n",
    "\n",
    "# Calculate user movement patterns\n",
    "logs['next_latitude'] = logs.groupby('user_id')['latitude'].shift(-1)\n",
    "logs['next_longitude'] = logs.groupby('user_id')['longitude'].shift(-1)\n",
    "\n",
    "# Filter meaningful movements\n",
    "movements = logs.dropna(subset=['next_latitude', 'next_longitude'])\n",
    "movements['distance'] = np.sqrt(\n",
    "    (movements['latitude'] - movements['next_latitude'])**2 + \n",
    "    (movements['longitude'] - movements['next_longitude'])**2\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### POI Analysis\n",
    "- Using a recommendation-like system to associate users with nearby POIs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DBSCAN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m     user_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m clustering\u001b[38;5;241m.\u001b[39mlabels_\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m user_data\n\u001b[0;32m---> 10\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mfinal_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muser_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcluster_user_locations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m data \u001b[38;5;241m=\u001b[39m data[data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# Filter noise\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Aggregate clusters into potential POIs\u001b[39;00m\n",
      "File \u001b[0;32m~/my_project/env1/lib/python3.12/site-packages/pandas/core/groupby/groupby.py:1824\u001b[0m, in \u001b[0;36mGroupBy.apply\u001b[0;34m(self, func, include_groups, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1822\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1823\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1824\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_apply_general\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selected_obj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1825\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1826\u001b[0m             \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, Series)\n\u001b[1;32m   1827\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1828\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selected_obj\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj_with_exclusions\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m   1829\u001b[0m         ):\n\u001b[1;32m   1830\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1831\u001b[0m                 message\u001b[38;5;241m=\u001b[39m_apply_groupings_depr\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1832\u001b[0m                     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1835\u001b[0m                 stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m   1836\u001b[0m             )\n",
      "File \u001b[0;32m~/my_project/env1/lib/python3.12/site-packages/pandas/core/groupby/groupby.py:1885\u001b[0m, in \u001b[0;36mGroupBy._python_apply_general\u001b[0;34m(self, f, data, not_indexed_same, is_transform, is_agg)\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   1851\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_python_apply_general\u001b[39m(\n\u001b[1;32m   1852\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1857\u001b[0m     is_agg: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1858\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NDFrameT:\n\u001b[1;32m   1859\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1860\u001b[0m \u001b[38;5;124;03m    Apply function f in python space\u001b[39;00m\n\u001b[1;32m   1861\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1883\u001b[0m \u001b[38;5;124;03m        data after applying f\u001b[39;00m\n\u001b[1;32m   1884\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1885\u001b[0m     values, mutated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_grouper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_groupwise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1886\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m not_indexed_same \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1887\u001b[0m         not_indexed_same \u001b[38;5;241m=\u001b[39m mutated\n",
      "File \u001b[0;32m~/my_project/env1/lib/python3.12/site-packages/pandas/core/groupby/ops.py:919\u001b[0m, in \u001b[0;36mBaseGrouper.apply_groupwise\u001b[0;34m(self, f, data, axis)\u001b[0m\n\u001b[1;32m    917\u001b[0m \u001b[38;5;66;03m# group might be modified\u001b[39;00m\n\u001b[1;32m    918\u001b[0m group_axes \u001b[38;5;241m=\u001b[39m group\u001b[38;5;241m.\u001b[39maxes\n\u001b[0;32m--> 919\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mutated \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_indexed_like(res, group_axes, axis):\n\u001b[1;32m    921\u001b[0m     mutated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[13], line 6\u001b[0m, in \u001b[0;36mcluster_user_locations\u001b[0;34m(user_data)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcluster_user_locations\u001b[39m(user_data):\n\u001b[1;32m      5\u001b[0m     coords \u001b[38;5;241m=\u001b[39m user_data[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatitude\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m----> 6\u001b[0m     clustering \u001b[38;5;241m=\u001b[39m \u001b[43mDBSCAN\u001b[49m(eps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0015\u001b[39m, min_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x, y: geodesic(x, y)\u001b[38;5;241m.\u001b[39mmeters)\u001b[38;5;241m.\u001b[39mfit(coords)\n\u001b[1;32m      7\u001b[0m     user_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m clustering\u001b[38;5;241m.\u001b[39mlabels_\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m user_data\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DBSCAN' is not defined"
     ]
    }
   ],
   "source": [
    "from scipy.spatial import cKDTree\n",
    "\n",
    "# Group by user and apply clustering\n",
    "def cluster_user_locations(user_data):\n",
    "    coords = user_data[['latitude', 'longitude']].values\n",
    "    clustering = DBSCAN(eps=0.0015, min_samples=2, metric=lambda x, y: geodesic(x, y).meters).fit(coords)\n",
    "    user_data['cluster'] = clustering.labels_\n",
    "    return user_data\n",
    "\n",
    "data = final_data.groupby('user_id').apply(cluster_user_locations)\n",
    "data = data[data['cluster'] != -1]  # Filter noise\n",
    "\n",
    "# Aggregate clusters into potential POIs\n",
    "clustered_pois = data.groupby(['cluster']).agg({\n",
    "    'latitude': 'mean',\n",
    "    'longitude': 'mean',\n",
    "    'user_id': 'count'\n",
    "}).rename(columns={'user_id': 'visit_count'}).reset_index()\n",
    "\n",
    "print(clustered_pois)\n",
    "\n",
    "# Build a KDTree for POIs\n",
    "poi_tree = cKDTree(pois[['latitude', 'longitude']])\n",
    "\n",
    "# Find nearest POIs for each tower\n",
    "distances, indices = poi_tree.query(towers[['latitude', 'longitude']], k=3)\n",
    "towers['nearby_pois'] = [pois.iloc[i]['name'].tolist() for i in indices]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Audience Segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.countplot(data=users, x='segment', hue='gender')\n",
    "plt.title('Audience Segmentation by Gender')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Movement Flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Visualize movement as flow\n",
    "fig = px.line_geo(movements, lat='latitude', lon='longitude', color='user_id',\n",
    "                  title='User Movement Patterns',)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### POI Proximity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Plot the POIs\n",
    "fig = px.scatter_mapbox(\n",
    "    pois,\n",
    "    lat=\"latitude\",\n",
    "    lon=\"longitude\",\n",
    "    text=\"name\",\n",
    "    color=\"category\",\n",
    "    zoom=15,\n",
    "    mapbox_style=\"open-street-map\",\n",
    "    title=\"Points of Interest on Oxford and Regent Streets\"\n",
    ")\n",
    "\n",
    "fig.add_scattergeo(lat=towers['latitude'], lon=towers['longitude'], \n",
    "                   mode='markers', name='Towers', marker=dict(color='blue'))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify Frequently Visited POIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "# Group by user and apply clustering\n",
    "def cluster_user_locations(user_data):\n",
    "    coords = user_data[['latitude', 'longitude']].values\n",
    "    clustering = DBSCAN(eps=0.0010, min_samples=2, metric=lambda x, y: geodesic(x, y).meters).fit(coords)\n",
    "    user_data['cluster'] = clustering.labels_\n",
    "    return user_data\n",
    "\n",
    "data = final_data.groupby('user_id').apply(cluster_user_locations)\n",
    "data = data[data['cluster'] != -1]  # Filter noise\n",
    "\n",
    "# Aggregate clusters into potential POIs\n",
    "clustered_pois = data.groupby(['cluster']).agg({\n",
    "    'latitude': 'mean',\n",
    "    'longitude': 'mean',\n",
    "    'user_id': 'count'\n",
    "}).rename(columns={'user_id': 'visit_count'}).reset_index()\n",
    "\n",
    "print(clustered_pois)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Matching POIs with Known Locations\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "# Build KDTree for POIs\n",
    "poi_tree = cKDTree(pois[['latitude', 'longitude']])\n",
    "\n",
    "# Match clustered POIs to known POIs\n",
    "distances, indices = poi_tree.query(clustered_pois[['latitude', 'longitude']], k=1)\n",
    "clustered_pois['nearest_poi'] = [pois.iloc[i]['name'] for i in indices]\n",
    "clustered_pois['poi_category'] = [pois.iloc[i]['category'] for i in indices]\n",
    "clustered_pois['distance_to_poi'] = distances\n",
    "\n",
    "print(clustered_pois)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualize the identified POIs and clusters using Plotly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter_mapbox(\n",
    "    clustered_pois,\n",
    "    lat=\"latitude\",\n",
    "    lon=\"longitude\",\n",
    "    color=\"poi_category\",\n",
    "    size=\"visit_count\",\n",
    "    hover_name=\"nearest_poi\",\n",
    "    mapbox_style=\"open-street-map\",\n",
    "    zoom=15,\n",
    "    title=\"Identified Points of Interest\"\n",
    ")\n",
    "\n",
    "fig.add_scattermapbox(\n",
    "    lat=pois['latitude'],\n",
    "    lon=pois['longitude'],\n",
    "    mode='markers',\n",
    "    marker=dict(size=10, color='red'),\n",
    "    name='Known POIs',\n",
    "    text=pois['name']\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
